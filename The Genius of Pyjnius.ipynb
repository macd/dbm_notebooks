{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Genius of Pyjnius\n",
    "### Using Pyjnius with Tika and the Stanford Core NLP\n",
    "#### Don MacMillen\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "[pyjnius](https://github.com/kivy/pyjnius) is a Python module to access Java classes that live in compiled jar files by using the Java Native Interface ([JNI](https://en.wikipedia.org/wiki/Java_Native_Interface))\n",
    "\n",
    "pyjnius is a subproject of the [kivy](https://github.com/kivy) project which is an open source cross platform Python framework for the applications development of user interfaces.\n",
    "\n",
    "I use pyjnius for interfacing with Apache [Tika](https://tika.apache.org/) and the Stanford [NLP](http://nlp.stanford.edu/) project.\n",
    "\n",
    "Since NLP uses Java 1.8, we need to have that installed.  On Ubuntu 14.04, I found it difficult to find a trusted ppa for OpenJDK, so I went with the Oracle JDK.\n",
    "\n",
    "To install it, do the following\n",
    "\n",
    "    sudo add-apt-repository ppa:webupd8team/java\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install oracle-java8-installer\n",
    "    \n",
    "You can verify by typing java -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "java version \"1.8.0_66\"\r\n",
      "Java(TM) SE Runtime Environment (build 1.8.0_66-b17)\r\n",
      "Java HotSpot(TM) 64-Bit Server VM (build 25.66-b17, mixed mode)\r\n"
     ]
    }
   ],
   "source": [
    "!java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to make certain that your JAVA_HOME environment variable is set.  I put it into my .bashrc\n",
    "\n",
    "    export JAVA_HOME=/usr/lib/jvm/java-8-oracle\n",
    "    \n",
    "and after sourcing .bashrc you can check that it is set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME=/usr/lib/jvm/java-8-oracle\r\n"
     ]
    }
   ],
   "source": [
    "!env | grep JAVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to install pyjnius.  For whatever reason, the version on pypi is 3 years old and limited to Python 2.7.  It is an active project, however, so we need to clone from github and build\n",
    "\n",
    "    git clone https://github.com/kivy/pyjnius.git\n",
    "    cd pyjnius\n",
    "    make\n",
    "    make test\n",
    "    python setup.py install\n",
    "    \n",
    "Using pyjnius and tika was first (for me) described [here](http://www.hackzine.org/using-apache-tika-from-python-with-jnius.html)\n",
    "\n",
    "We need the tika application jar.  We can get that by [here](https://tika.apache.org/download.html) and put it someplace convenient.\n",
    "\n",
    "Now we are ready to extract some text.\n",
    "\n",
    "We have to set the classpath environment variable and that can be done either with os.environ or with jnius_config command.  I have also added the directory for the Stanford NLP Core library example that is used later.  You will have to download those jars from the NLP website mentioned earlier.\n",
    "\n",
    "jnius_config command must be imported and set **before** importing the jnius module.  That's because importing jnius actually launches a JVM.  The options -Xmx4G tell the JVM it can use a cache size up to 4GB. The default cache size is too small.\n",
    "\n",
    "We also need to up the number of maximum characters to consider.  This must be done separately for the input and the output.  The following code shows how."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "os.environ['CLASSPATH'] = (\"/home/fermi/tikajars/*:\"\n",
    "                           \"/home/fermi/snlp/stanford-corenlp-full-2015-12-09/*\")\n",
    "\n",
    "import jnius_config\n",
    "jnius_config.add_options('-Xmx4G')\n",
    "\n",
    "import jnius\n",
    "from jnius import autoclass\n",
    "from jnius import JavaException\n",
    "\n",
    "# Import Java classes\n",
    "Tika = autoclass('org.apache.tika.Tika')\n",
    "Metadata = autoclass('org.apache.tika.metadata.Metadata')\n",
    "AutoDetectParser = autoclass('org.apache.tika.parser.AutoDetectParser')\n",
    "ParseContext = autoclass('org.apache.tika.parser.ParseContext')\n",
    "BodyContentHandler = autoclass('org.apache.tika.sax.BodyContentHandler')\n",
    "LanguageIdentifier = autoclass('org.apache.tika.language.LanguageIdentifier')\n",
    "FileInputStream = autoclass('java.io.FileInputStream')\n",
    "\n",
    "MAX_CHARACTERS = 30*1024*1024\n",
    "\n",
    "# Besides getting the metadata, this also extracts the text\n",
    "def get_meta(fname):\n",
    "    '''\n",
    "    Return the file meta data as a dict as well as the body text\n",
    "    of the file.  Tika will automatically figure out file type and\n",
    "    extract the text.\n",
    "    '''\n",
    "    tika = Tika()\n",
    "    \n",
    "    tika.setMaxStringLength(MAX_CHARACTERS)\n",
    "    parser = AutoDetectParser()\n",
    "    handler = BodyContentHandler(MAX_CHARACTERS)  # number is max chars to write\n",
    "    meta = Metadata()\n",
    "    inputstream = FileInputStream(fname)\n",
    "    context = ParseContext()\n",
    "    \n",
    "    parser.parse(inputstream, handler, meta, context)\n",
    "    \n",
    "    mdict = dict((name, meta.get(name)) for name in meta.names())\n",
    "    return (mdict, handler.toString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdict, txt = get_meta('./data/nnnn.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "access_permission:extract_content true\n",
      "access_permission:extract_for_accessibility true\n",
      "access_permission:modify_annotations true\n",
      "created Thu Mar 13 05:25:09 PDT 2008\n",
      "Content-Type application/pdf\n",
      "Last-Save-Date 2008-03-13T12:27:15Z\n",
      "access_permission:assemble_document true\n",
      "Creation-Date 2008-03-13T12:25:09Z\n",
      "dcterms:modified 2008-03-13T12:27:15Z\n",
      "meta:creation-date 2008-03-13T12:25:09Z\n",
      "producer Acrobat Distiller 6.0.1 (Windows)\n",
      "xmp:CreatorTool Arbortext Advanced Print Publisher 9.0.114/W\n",
      "dc:title 10055_2008_84_12_1-web 17..25\n",
      "access_permission:fill_in_form true\n",
      "dcterms:created 2008-03-13T12:25:09Z\n",
      "pdf:encrypted false\n",
      "access_permission:can_print_degraded true\n",
      "date 2008-03-13T12:27:15Z\n",
      "pdf:PDFVersion 1.3\n",
      "X-Parsed-By org.apache.tika.parser.DefaultParser\n",
      "access_permission:can_print true\n",
      "title 10055_2008_84_12_1-web 17..25\n",
      "modified 2008-03-13T12:27:15Z\n",
      "xmpTPg:NPages 9\n",
      "access_permission:can_modify true\n",
      "meta:save-date 2008-03-13T12:27:15Z\n",
      "dc:format application/pdf; version=1.3\n",
      "Last-Modified 2008-03-13T12:27:15Z\n"
     ]
    }
   ],
   "source": [
    "for k, v in mdict.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ORIGINAL ARTICLE\n",
      "\n",
      "FARMTASIA: an online game-based learning environment\n",
      "based on the VISOLE pedagogy\n",
      "\n",
      "Kevin K. F. Cheung Æ Morris S. Y. Jong Æ\n",
      "F. L. Lee Æ Jimmy H. M. Lee Æ Eric T. H. Luk Æ\n",
      "Junjie Sha\n"
     ]
    }
   ],
   "source": [
    "print(txt[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the 'problems' with using pyjnius is that the objects that are returned are not very 'Pythonic'.  For example, a Java list is **not** a Python list, as the following clearly shows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__cls_storage', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__gt__', '__hash__', '__init__', '__javaclass__', '__javaconstructor__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'add', 'addAll', 'clear', 'clone', 'contains', 'containsAll', 'ensureCapacity', 'equals', 'forEach', 'get', 'getClass', 'hashCode', 'indexOf', 'isEmpty', 'iterator', 'lastIndexOf', 'listIterator', 'mpty', 'notify', 'notifyAll', 'parallelStream', 'remove', 'removeAll', 'removeIf', 'replaceAll', 'retainAll', 'set', 'size', 'sort', 'spliterator', 'stream', 'subList', 'toArray', 'toString', 'trimToSize', 'wait']\n",
      "[aaa, eee, hhh]\n",
      "jl.__class__ <class 'jnius.reflect.java.util.ArrayList'>\n"
     ]
    }
   ],
   "source": [
    "ArrayList = autoclass('java.util.ArrayList')\n",
    "jl = ArrayList()\n",
    "print(dir(jl))\n",
    "jl.add('aaa')\n",
    "jl.add('eee')\n",
    "jl.add('hhh')\n",
    "print(jl.toString())\n",
    "print('jl.__class__', jl.__class__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am not going to try to reproduce the full list object behavior for the Java ArrayList type, but we can make a Python class that will make iteration over these Javaesque objects just a little less ugly (and be useful for other classes that have the Java iteration() method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n",
      "eee\n",
      "hhh\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Make iteration over Java objects a little less ugly\n",
    "class Jiter():\n",
    "    def __init__(self, jobj):\n",
    "        self.jobj = jobj\n",
    "\n",
    "    def __iter__(self):\n",
    "        iter = self.jobj.iterator()\n",
    "        while iter.hasNext():\n",
    "            yield iter.next()\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.jobj.size()\n",
    "\n",
    "pl = Jiter(jl)\n",
    "for item in pl:\n",
    "    print(item)\n",
    "    \n",
    "print(len(pl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we show the Python version of ShiftReduceDemo.java that is shipped with the Core NLP code.  One (of the many) differences in the Python version is that we do not need all the abstract classes that are strewn around in the Java code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "StringReader = autoclass('java.io.StringReader')\n",
    "\n",
    "ShiftReduceParser = autoclass('edu.stanford.nlp.parser.shiftreduce.ShiftReduceParser')\n",
    "DocumentPreprocessor = autoclass('edu.stanford.nlp.process.DocumentPreprocessor')\n",
    "MaxentTagger = autoclass('edu.stanford.nlp.tagger.maxent.MaxentTagger')\n",
    "\n",
    "model_path = \"edu/stanford/nlp/models/srparser/englishSR.ser.gz\"\n",
    "tagger_path = \"edu/stanford/nlp/models/pos-tagger/english-left3words/english-left3words-distsim.tagger\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "demo_text = (\"My dog likes to shake his stuffed chickadee toy.\\n\"\n",
    "             \"The truth will set you free only when the truth is freely available.\")\n",
    "    \n",
    "tagger = MaxentTagger(tagger_path)\n",
    "model = ShiftReduceParser.loadModel(model_path)\n",
    "strdr = StringReader(demo_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we come up against a bug in pyjnius.\n",
    "\n",
    "We want to create a new tokenizer from the DocumentPreprocessor class.  The class constructor can take either a Reader object (but this is an abstract class), or a string that is a path name to a file.  We'd like to pass in a StringReader object (subclassed from Reader) and this should be OK but pyjnius thinks it is not and throws an error.\n",
    "\n",
    "    ---> 84     tokenizer = DocumentPreprocessor(StringReader(text))\n",
    "         85 \n",
    "         86     print('strdr class: ', strdr.__class__)\n",
    "\n",
    "    jnius/jnius_export_class.pxi in jnius.JavaClass.__init__ (jnius/jnius.c:18610)()\n",
    "\n",
    "    jnius/jnius_export_class.pxi in jnius.JavaClass.call_constructor (jnius/jnius.c:19719)()\n",
    "\n",
    "    jnius/jnius_conversion.pxi in jnius.populate_args (jnius/jnius.c:8323)()\n",
    "\n",
    "    jnius/jnius_utils.pxi in jnius.check_assignable_from (jnius/jnius.c:5607)()\n",
    "\n",
    "    JavaException: Invalid instance of 'java/io/StringReader' passed for a 'java/lang/String'\n",
    "\n",
    "There are actually five different signatures for the constructor for DocumentPreprocessor.  They are \n",
    "\n",
    "    public DocumentPreprocessor(Reader input) {\n",
    "    public DocumentPreprocessor(Reader input, DocType t) {\n",
    "    public DocumentPreprocessor(String docPath) {\n",
    "    public DocumentPreprocessor(String docPath, DocType t) {\n",
    "    public DocumentPreprocessor(String docPath, DocType t, String encoding) {\n",
    "\n",
    "So what to do? Well, we hack and fool pyjnius into thinking it is OK (and yes, I did file an issue on pyjnius)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Reader = autoclass('java.io.Reader')\n",
    "strdr.__class__ = Reader  # I will burn in the Python hell for this.\n",
    "tokenizer = DocumentPreprocessor(strdr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the tokenizer is an iterator over sentences in the source text.  For each sentence, we will first pass it to be tagged.  Then the tagged sentence can be parsed into a grammatical parse tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trees = []\n",
    "for sentence in Jiter(tokenizer):\n",
    "    tagged = tagger.tagSentence(sentence)\n",
    "    trees.append(model.apply(tagged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we can take a look at our parse trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(ROOT (S (NP (PRP$ My) (NN dog)) (VP (VBZ likes) (S (VP (TO to) (VP (VB shake) (NP (PRP$ his) (VBN stuffed) (NN chickadee) (NN toy)))))) (. .))) \n",
      "\n",
      "(ROOT (S (NP (DT The) (NN truth)) (VP (MD will) (VP (VB set) (NP (PRP you)) (ADVP (JJ free)) (SBAR (WHADVP (RB only) (WRB when)) (S (NP (DT the) (NN truth)) (VP (VBZ is) (ADJP (RB freely) (JJ available))))))) (. .))) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tree in trees:\n",
    "    print(tree.toString(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Very cool."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
