{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted minhashing\n",
    "## Don MacMillen\n",
    "\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-sa/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.\n",
    "\n",
    "You will have better results viewing this notebook on the nbviewer hosted by the Jupyter project rather than on github.  Look at the following:\n",
    "\n",
    "https://nbviewer.jupyter.org/github/macd/dbm_notebooks/blob/master/weighted_minhashing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook that implements and (eventually) compares the QoR and runtime of the weighted min hashing schemes of Ioffe [1] and Shrivastava [2].  It is very much a work in progress at the moment.\n",
    "\n",
    "We first implement Ioffe's method and we start with some global state and scratch space (to avoid re-allocating) for the minhash algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WMinIHash"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributions\n",
    "\n",
    "\n",
    "immutable WMinIHash\n",
    "    # Pre-calculated random state\n",
    "    master_seed::Tuple{Int, Int}\n",
    "    r::Array{Float64, 2}\n",
    "    lc::Array{Float64, 2}\n",
    "    beta::Array{Float64, 2}\n",
    "    \n",
    "    # scratch space for minhash\n",
    "    t::Vector{Int}\n",
    "    la::Vector{Float64}\n",
    "    ly::Vector{Float64}\n",
    "end\n",
    "\n",
    "\n",
    "function WMinIHash(nfeatures, numhash, master_seed)\n",
    "    # So, as of 21 Aug 2016, the Distributions package only uses\n",
    "    # Base.GLOBAL_RNG as its source of entropy. Bummer.\n",
    "    srand(master_seed[1])\n",
    "    gma = Gamma(2, 1)\n",
    "    r = rand(gma, nfeatures, numhash)\n",
    "    srand(master_seed[2])\n",
    "    gmb = Gamma(2, 1)\n",
    "    lc = log.(rand(gmb, nfeatures, numhash))\n",
    "    beta = rand(nfeatures, numhash)\n",
    "    t = zeros(Int, nfeatures)\n",
    "    la = ones(nfeatures)\n",
    "    ly = zeros(nfeatures)\n",
    "    wmih = WMinIHash(master_seed, r, lc, beta, t, la, ly)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the heart of the Ioffe algo.  It follows the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i_minhash! (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mintuples is pre-allocated (but reinit still uses mem?)\n",
    "function i_minhash!(x, w, mintuples)\n",
    "    nf, nh = size(w.r)\n",
    "    # What is best init for mintuples?\n",
    "    mintuples[:] = (0, 0)\n",
    "    for h = 1:nh\n",
    "        w.t[:] = 0\n",
    "        w.la[:] = typemax(eltype(w.la))   # because we take the min later\n",
    "        w.ly[:] = 0.0\n",
    "        for k in 1:nf\n",
    "            x[k] == 0.0 && continue\n",
    "            w.t[k] = floor(log(x[k]) / w.r[k, h] + w.beta[k, h])\n",
    "            w.ly[k] = w.r[k, h] * (w.t[k] - w.beta[k, h])\n",
    "            w.la[k] = w.lc[k, h] - w.ly[k] - w.r[k, h]\n",
    "        end\n",
    "        kstar = indmin(w.la)\n",
    "        mintuples[h] = (kstar, Int(w.t[kstar]))\n",
    "    end\n",
    "    return mintuples\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need the test scaffolding to exercise.  This needs more thought and more work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max error: 0.1716871583805694\n"
     ]
    }
   ],
   "source": [
    "function i_minhash_all!(fp, md, wmih)\n",
    "    ndata, nfeatures = size(md)\n",
    "    M = nfeatures\n",
    "    _, nhashes = size(fp)\n",
    "    mintuples = Vector{Tuple{Int, Int}}(nhashes)\n",
    "    for i in 1:ndata\n",
    "        fp[i, :] = i_minhash!(md[i, :], wmih, mintuples)\n",
    "    end\n",
    "    nothing\n",
    "end\n",
    "\n",
    "\n",
    "function syndata(nrows, ncols, scale=1.0)\n",
    "    rng = MersenneTwister(1137)\n",
    "    #srand(1137)\n",
    "    #rng = Weibull()\n",
    "    md = scale * rand(rng, nrows, ncols)\n",
    "    return md\n",
    "end\n",
    "\n",
    "wsim(x, y) = sum(min.(x, y)) / sum(max.(x, y))\n",
    "\n",
    "# Pick one vector to compare the others to\n",
    "const COMPARE = 51\n",
    "\n",
    "\n",
    "function test_ioffe(nhashes=256, ndata=500, nfeatures=128)\n",
    "    m = ones(nfeatures)\n",
    "    scale = 1.0\n",
    "    md = syndata(ndata, nfeatures, scale)\n",
    "\n",
    "    iwmh = WMinIHash(nfeatures, nhashes, (919, 1137))\n",
    "    finger_prints = Matrix{Tuple{Int, Int}}(ndata, nhashes)\n",
    "    i_minhash_all!(finger_prints, md, iwmh)    \n",
    "\n",
    "    error = []\n",
    "    for i in 1:ndata\n",
    "        x = finger_prints[i, :]\n",
    "        y = finger_prints[COMPARE, :]\n",
    "        sim = sum(x .== y) / nhashes\n",
    "        exact_sim = wsim(md[i, :], md[COMPARE, :])\n",
    "        push!(error, ((sim - exact_sim)/exact_sim, i))\n",
    "    end\n",
    "    #for (err, i) in sort(error)\n",
    "    #    println(err, \"   \", i)\n",
    "    #end\n",
    "    # TODO: plot a histogram of the errors\n",
    "    # TODO: plot max error vs. the number of hashes\n",
    "    # TODO: vary the size, number, and sparsity of the data vectors\n",
    "    println(\"max error: \", maximum([abs(x[1]) for x in error]))\n",
    "end\n",
    "\n",
    "test_ioffe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for Shrivastava's red / green weighted minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WMinHash"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Random: mt_setempty!, MTCacheLength\n",
    "\n",
    "# Reseeding the rng's inside an inner loop is a bad idea with the\n",
    "# current implementation of MersenneTwister.  This is because it\n",
    "# calls dsfmt_init_by_array which does a _lot_ of processing.\n",
    "# In many cases we want to reset the seeds to those already seen, \n",
    "# so we cache a copy of the rng and restore if we find it in the cache.\n",
    "\n",
    "rng_cache = Dict{Int, MersenneTwister}()\n",
    "\n",
    "function rsrand(r::MersenneTwister, n::Int)\n",
    "    if haskey(rng_cache, n)\n",
    "        copy!(r, rng_cache[n])\n",
    "    else\n",
    "        srand(r, n)\n",
    "        rng_cache[n] = copy(r)\n",
    "    end\n",
    "    return r\n",
    "end\n",
    "\n",
    "\n",
    "type WMinHash\n",
    "    master_seed::Int\n",
    "    m::Vector{Float64}\n",
    "    rng::MersenneTwister\n",
    "    seeds::Vector{Int}\n",
    "    M::Int\n",
    "    int2compM::Vector{Tuple{Int, Int}}\n",
    "end\n",
    "\n",
    "\n",
    "function WMinHash(max_hashes::Int, master_seed::Int, m::Vector{Float64})\n",
    "    rng = MersenneTwister(master_seed)\n",
    "    seeds = [abs(x) for x in rand(rng, Int, max_hashes)]\n",
    "    wmh = WMinHash(master_seed, copy(m), rng, seeds, ceil(sum(m)), calc_arraymap(m))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that out of the way, we can implement the three functions that are in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isgreen (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calc_arraymap(m)\n",
    "    int2compM = Vector{Tuple{Int, Int}}()\n",
    "    D = length(m)\n",
    "    Mi = 0\n",
    "    for i = 1:D\n",
    "        mi = ceil(Int, m[i])\n",
    "        for j = 1:mi\n",
    "             push!(int2compM, (i, Mi))\n",
    "        end\n",
    "        Mi += mi\n",
    "    end\n",
    "    return int2compM\n",
    "end\n",
    "\n",
    "\n",
    "function rg_minhash!(x, wmh::WMinHash, hashes::Vector{Int})\n",
    "    num_hashes = length(hashes)\n",
    "    num_hashes > length(wmh.seeds) && error(\"too many hashes\")\n",
    "    # (re) initialize the hashes\n",
    "    hashes[:] = 0\n",
    "    @inbounds for i = 1:num_hashes\n",
    "        rsrand(wmh.rng, wmh.seeds[i])\n",
    "        while true\n",
    "            r = wmh.M * rand(wmh.rng)::Float64\n",
    "            isgreen(r, x, wmh) && break\n",
    "            rsrand(wmh.rng, ceil(Int, 1e6 * r))\n",
    "            hashes[i] += 1\n",
    "        end\n",
    "    end\n",
    "    hashes\n",
    "end\n",
    "\n",
    "\n",
    "function isgreen(r, x, wmh)\n",
    "    index = ceil(Int, r)\n",
    "    i, Mi = wmh.int2compM[index]\n",
    "    if r <= Mi + x[i]\n",
    "        return true\n",
    "    end\n",
    "    return false\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the test scaffolding for red / green minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max error: 0.1612122653955883\n"
     ]
    }
   ],
   "source": [
    "function w(i, j)\n",
    "    return wsim(md[i, :], md[j, :])\n",
    "end\n",
    "\n",
    "function es(i, j)\n",
    "    _, nfeatures = size(finger_prints)\n",
    "    return sum(finger_prints[i,:] .== finger_prints[j,:]) / nfeatures\n",
    "end\n",
    "\n",
    "function rg_minhash_all!(fp, md, wmh)\n",
    "    ndata, nfeatures = size(md)\n",
    "    # assume each component of x is bounded by one. Not true in general\n",
    "    M = nfeatures\n",
    "    _, nhashes = size(fp)\n",
    "    hashes = zeros(Int, nhashes)\n",
    "    for i in 1:ndata\n",
    "        fp[i, :] = rg_minhash!(md[i, :], wmh, hashes)\n",
    "    end\n",
    "    nothing\n",
    "end\n",
    "\n",
    "# Make these global for debugging at the repl\n",
    "md = Matrix{Float64}()\n",
    "finger_prints = Matrix{Float64}()\n",
    "\n",
    "# if both x[i] and y[i] are zero, then use 1 in the denom instead of zero.\n",
    "@inline function esim(x, y)\n",
    "    return sum(1.0 - (abs.(x .- y) ./ max.(1, x, y))) / length(x)\n",
    "end\n",
    "\n",
    "function test_rg(nhashes=256, ndata=500, nfeatures=128)\n",
    "    global md, finger_prints\n",
    "    md = syndata(ndata, nfeatures)\n",
    "    #md = weibulldata(ndata, nfeatures)\n",
    "    \n",
    "    m = ones(nfeatures)\n",
    "    wmh = WMinHash(1000000, 1137, m)\n",
    "    finger_prints = zeros(Int, ndata, nhashes)\n",
    "\n",
    "    rg_minhash_all!(finger_prints, md, wmh)\n",
    "    fp = copy(finger_prints[51, :])\n",
    "    error = []\n",
    "    for i in 1:ndata\n",
    "        sim1 = sum(finger_prints[i, :] .== fp) / nhashes\n",
    "        sim2 = esim(finger_prints[i, :], fp)\n",
    "        exact_sim = wsim(md[i, :], md[51, :])\n",
    "        push!(error, ((sim1 - exact_sim)/exact_sim, exact_sim, sim1, sim2, i))\n",
    "    end\n",
    "    #for (err, exs, s1, s2, i) in sort(error)\n",
    "    #    println(err, \"   \", exs, \"   \", s1, \"   \", s2, \"   \", i)\n",
    "    #end\n",
    "    println(\"max error: \", maximum([abs(x[1]) for x in error]))\n",
    "end\n",
    "\n",
    "test_rg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max error: 0.07574762798830523\n",
      "  1.147462 seconds (2.13 M allocations: 123.812 MB, 5.43% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time test_rg(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max error: 0.07796156862226696\n",
      "  1.905385 seconds (11.85 k allocations: 33.089 MB, 0.15% gc time)\n"
     ]
    }
   ],
   "source": [
    "@time test_ioffe(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, well, they both seem to be working, with the red / green hashing getting slightly smaller max errors for the same number of hashes.   It also looks like red green is about 1.7 times faster **but** I may have some memory / type issues with the r/g code (see the 2.13 M allocations).  Will need to debug later. **Need to test much more and get detailed timings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "[1] S. Ioffe, \"Improved consistent sampling, weighted minhash and L1 sketching\", In ICDM, pp. 246-255, Sydney, AU, 2010\n",
    "\n",
    "[2] A. Shrivastava, \"Simple and Efficient Weighted Minwise Hashing\", NIPS, Barcelona, 2016"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.0-dev",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
